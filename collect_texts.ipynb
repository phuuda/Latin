{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all author links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n"
     ]
    }
   ],
   "source": [
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "home = \"http://latin.packhum.org/browse\"\n",
    "\n",
    "author_links = [] # each element: [author name, author link]\n",
    "\n",
    "def get_links(soup):\n",
    "\n",
    "    np_link = ''\n",
    "    \n",
    "    for tag in soup.findAll('a'): # find tags that contain links\n",
    "        link = tag['href']\n",
    "        match = re.findall('/author/[0-9]+', link) # find all links in this format\n",
    "        if match:\n",
    "    \n",
    "            np_link = 'http://latin.packhum.org' + match[0] # create whole link\n",
    "        \n",
    "            author_name = tag.findAll('span')\n",
    "            author_name = author_name[0].text # get author name\n",
    "        \n",
    "            if np_link not in author_links:\n",
    "                author_links.append([author_name, np_link])\n",
    "                \n",
    "req = requests.get(\"http://latin.packhum.org/browse\") # the page where we search for author links\n",
    "soup = BeautifulSoup(req.text, 'lxml')\n",
    "\n",
    "get_links(soup) # calls function to collect all author links\n",
    "print(len(author_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all text links from \"author_links\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "text_links = [] # each element: [author name, text name, text link]\n",
    "\n",
    "def get_text_links(soup, author_name):\n",
    "\n",
    "    np_link = ''\n",
    "    \n",
    "    for tag in soup.findAll('a'):\n",
    "        link = tag['href']\n",
    "        match = re.findall('/loc/.*$', link) # finds all links to texts\n",
    "        if match:\n",
    "        \n",
    "            text_name = tag.findAll('span')\n",
    "            text_name = text_name[1].text\n",
    "            \n",
    "            print(match[0] + ' ' + author_name + ' ' + text_name)\n",
    "            \n",
    "            np_link = 'http://latin.packhum.org' + match[0] # create whole link\n",
    "            print(np_link)\n",
    "            \n",
    "            if np_link not in text_links:\n",
    "                text_links.append([author_name, text_name, np_link])\n",
    "                \n",
    "for i in author_links:\n",
    "    author_name = i[0]\n",
    "    author_link = i[1]\n",
    "    req = requests.get(author_link) # the page where we search for text links\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    \n",
    "    get_text_links(soup, author_name) # calls function to collect all links to texts\n",
    "    \n",
    "print(len(text_links))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all texts from \"text_links\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_texts = [] # each element: [author, text name, text]\n",
    "\n",
    "def get_texts(author, text_name, text_link):\n",
    "    \n",
    "    req = requests.get(text_link)\n",
    "    soup = BeautifulSoup(req.text, 'lxml')\n",
    "    \n",
    "    file_name = author + ' - ' + text_name + '.txt' # unique name for text\n",
    "    \n",
    "    f = open(file_name, 'w', encoding = 'utf-8') # creates new file for a text\n",
    "    \n",
    "    whole_text = ''\n",
    "    for tag in soup.findAll('table'):\n",
    "\n",
    "        for tr in tag.findAll('tr'): # finds all tags with text\n",
    "            line = tr.text\n",
    "\n",
    "            while '\\n' in line: # deleting empty lines \n",
    "                line = line.replace('\\n', '')\n",
    "\n",
    "            while '                           ' in line: # deleting extra spaces\n",
    "                line = line.replace('                           ', '          ')\n",
    "            line = line.lstrip() # deleting extra spaces \n",
    "            \n",
    "            whole_text += line\n",
    "            whole_text += '\\n'\n",
    "            \n",
    "    f.write(whole_text)          \n",
    "    f.close()\n",
    "    \n",
    "    all_texts.append([author, text_name, whole_text])\n",
    "    \n",
    "    print(author + ' - ' + text_name)\n",
    "    \n",
    "for item in text_links:\n",
    "    author = item[0]\n",
    "    text_name = item[1]\n",
    "    text_link = item[2]\n",
    "    \n",
    "    get_texts(author, text_name, text_link) # creates new file for each text\n",
    "                                            # the texts are now also in 'all_texts'\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text from each file, save into \"all_texts.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "836\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "texts = [] # each element is [author and text name, text]\n",
    "\n",
    "path = 'text files/'\n",
    "\n",
    "for filename in glob.glob(os.path.join(path, '*.txt')): # finds all .txt in 'text files' folder\n",
    "\n",
    "    f = open(filename, 'r', encoding = 'utf-8')\n",
    "    text = f.read()\n",
    "    \n",
    "    texts.append([filename, text])\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "print(len(texts))\n",
    "\n",
    "f1 = open('all_texts.txt', 'w', encoding = 'utf-8') # new file for all texts\n",
    "\n",
    "for item in texts:\n",
    "    filename = item[0]\n",
    "    text = item[1]\n",
    "    \n",
    "    f1.write(filename)\n",
    "    f1.write('\\n\\n')\n",
    "    f1.write(text)\n",
    "    f1.write('-----------------------------------------------')\n",
    "    f1.write('\\n')\n",
    "    \n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
